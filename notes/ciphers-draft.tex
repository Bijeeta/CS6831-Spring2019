%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Ciphers and Initial Security Notions}
\label{sec:se}

\paragraph{Ciphers.}
We start by defining a cipher. A cipher $\cipher = (\cipherE,\cipherD)$ is
defined by a pair of deterministic algorithms $\cipherE$ and $\cipherD$.  To
any cipher $\cipher$ we associate sets called the key space $\keyspace$, message
space $\msgspace$, and ciphertext space $\ctxtspace$. We do not surface these sets in the
notation for a cipher, and we will require that the association be clear
from context.

Each algorithm has two inputs. Enciphering takes a key $K \in \keyspace$ and
message $M \in \msgspace$, and outputs a ciphertext $C \in \ctxtspace$. Because
$\cipherE$ is deterministic, we can equally formalize it as a map 
$\cipherE\Colon\keyspace\times\msgspace\rightarrow\ctxtspace$. For a given key
$K$ we let $\cipherE_K\Colon\msgspace\rightarrow\ctxtspace$ be defined by
$\cipherE_K(M) = \cipherE(K,M)$ for all $M \in \msgspace$.  Deciphering takes a key $K\in \keyspace$ and ciphertext
$C \in \ctxtspace$ and outputs a message $M \in \msgspace$. Again, we can view
it as a map $\cipherD\Colon\keyspace\times\ctxtspace\rightarrow\msgspace$. 

Both $\cipherE$ and $\cipherD$ must be efficiently computable for all $K \in
\keyspace$.  (We have not defined efficiently computable and use the term here
informally.) We require that a cipher be correct, meaning that
$\forall M \in \msgspace, \forall K \in \keyspace$, it holds that $\cipherD_K(\cipherE_K(M)) = M$.

\begin{example} One simple example of a cipher is the \textbf{one-time pad} (OTP). Let $\keyspace = \msgspace=\ctxtspace=\{0,1\}^n$ for some $n \in \N$. Then for any key $K\getsr\keyspace$ and for any message $M \in \msgspace$, we define the OTP as follows:
\begin{equation*}
\cipherE_K(M) = M \oplus K \qquad
\cipherD_K(C) = C \oplus K
\end{equation*}
Claude Shannon proved that the OTP is perfectly secure for one-time use in 1949 \cite{shannon1949communication}. Intuitively, we expect a cipher to be \textbf{perfectly secure} if a ciphertext provides no information about the message.
Formally, a cipher is perfectly secure if for any $M_1, M_2 \in \msgspace$, any $K \in \keyspace$, and any $C \in \ctxtspace$, 
\begin{equation*}
\Prob{K \getsr \keyspace: \cipherE_{K}(M_1) = C} = \Prob{K \getsr \keyspace: \cipherE_{K}(M_2) = C}.
\end{equation*}
Notice that although the OTP is perfectly secure, it is not practical since the key must be as large as the message. 
\end{example}

\paragraph{Security notions.} What do we intuitively expect of a cipher?
Minimally:
\begin{itemize}
\item The secret key should remain secret.
\item The message should remain secret.
\end{itemize}

\begin{wrapfigure}[13]{r}{0pt}
	\fpage{.15}{
		\underline{$\TKR^\advA_\cipher$}\\[1pt]
		$K \getsr \keyspace$\\
		$K^* \getsr \advA^\Fn$\\
		Return $(K = K^*)$\medskip
		
		\underline{$\Fn(M)$}\\
		$C \gets \cipherE_K(M)$\\
		Return $C$
	}
	\caption{The target key recovery game.}
	\label{fig:tkr}
\end{wrapfigure}

Let's try to formalize these ideas. We will start with a security notion called \textbf{target key recovery security} (TKR).
As the name suggests, the goal of the adversary is to recover the challenge key given a chosen plaintext attack, meaning the adversary can choose which messages for which it will receive the corresponding ciphertexts. In the $\TKR_\cipher$ game, the adversary makes the queries for these messages to what is called the $\Fn$ oracle. On input $M$, the $\Fn$ oracle simply returns the corresponding ciphertext $C \gets \cipherE_K(M)$, thereby hiding information about key $K$ from the adversary. 
 The game pseudocode is provided in \figref{fig:tkr}. We let $\TKR_\cipher$-advantage of a $\TKR_\cipher$-adversary $\advA$ be defined by 
\bnm
\AdvTKR{\cipher}{\advA} = \Prob{\TKR^\advA_\cipherE \Rightarrow\true}  \;.
\enm

We must now ask ourselves how well TKR captures the security of a cipher. Let us first try to analyze the security of the OTP using this definition. Notice that the OTP actually fails to provide TKR security, which we show with the following adversary.
\begin{center}
	\fpage{.15}{
		\underline{\textbf{adversary }$\advA$}\\[2pt]
		$K \gets \Fn(0^n)$ \\
		Return $K$
	}
\end{center}	

$\advA$ simply queries for $0^n$, which returns $0^n \oplus K = K$, thereby recovering the challenge key with $\AdvTKR{\cipher}{\advA} = 1$. This then means that the OTP is actually insecure according to the TKR security definition. But as we noted earlier, the OTP is considered perfectly secret! Our definition then fails to capture the goal of perfect secrecy. \pfreadernote{say something about implications, 2-time security}

Now consider the identity cipher $\cipherE_{K}(M) = M$ for $\keyspace=\{0,1\}^k$. Since the cipher simply returns the message, no information about the key is included in the ciphertext. The best an adversary can do is return a random key, which has probability $2^{-k}$ of being the correct target key.
Then for any adversary $\advA$, it holds that $\AdvTKR{\cipher}{\advA} = 2^{-k}$, meaning the identity cipher is ``secure''. However, the identity cipher clearly does not provide message confidentiality, and thus our TKR notion says nothing about this property.

\begin{wrapfigure}[17]{r}{0pt}
	\fpage{.25}{
		\underline{$\KR^\advA_\cipher$}\\[1pt]
		$\win \gets \false$\\
		$K \getsr \keyspace$\\
		$K^* \getsr \advA^\Fn$\\ 
		For $M \in \calX$:\\
		\ind If $\cipherE_{K^*}(M) \ne \cipherE_{K}(M)$ then\\
		\ind\ind $\win \gets \false$\\
		Return $\win$\medskip
		
		\underline{$\Fn(M)$}\\
		$\win \gets \true$ \\
		$\calX \gets \calX \cup \{M\}$\\
		$C \gets \cipherE_K(M)$\\
		Return $C$
	}
	\caption{The key recovery game.}
	\label{fig:kr}
\end{wrapfigure}

Furthermore, this security notion is ``unfair'' to an adversary, since there can be many keys that are \textit{consistent} on a query transcript. We then look at a different notion called \textbf{key recovery security} (KR). Under this definition, if an adversary outputs a key that is consistent with the query transcript, then it wins. The game pseudocode is provided in \figref{fig:kr}. Notice that if an adversary makes no queries to the $\Fn$ oracle, then $\KR_\cipherE$ will return $\false$.
We let $\KR_\cipher$-advantage of a $\KR_\cipher$-adversary $\advA$ be defined by 
\bnm
\AdvKR{\cipher}{\advA} = \Prob{\KR^\advA_\cipherE \Rightarrow\true}  \;.
\enm

How does KR compare to TKR? We now look at how to formally compare security definitions to gain an understanding of the relationship between TKR and KR. 

\paragraph{Comparing security definitions.} To show that some definition DEF1 does not imply another definition DEF2, we can show a \textit{counter-example}. This requires producing a scheme such that we can show that no (reasonable) DEF1-adversary has a good advantage. We then give a DEF2-adversary that does maintain a good DEF2 advantage (perhaps under some assumption, such as the existence of a DEF2-secure scheme). 

Conversely, to show that DEF1 does imply DEF2, we can show a \textit{reduction}. This requires converting a DEF2-adversary $\advA$ into a DEF1-adversary $\advB$ such that $\advB$'s DEF1 advantage upper bounds $\advA$'s DEF2 advantage. Moreover, the resources, such as number of queries and running time, of $\advB$ should be close to that of $\advA$.

\begin{example}
TKR $\not \Rightarrow$ KR \\
To show this, we need a counter-example, and in this case we can use the identity cipher $\cipherE_{K}(M) = M$ for $\keyspace=\{0,1\}^k$ and $\msgspace=\{0,1\}^n$. 
We have already discussed that any adversary cannot get a TKR advantage greater than $2^{-k}$. Next we must provide a KR-adversary that achieves a ``good'' advantage. We construct a KR-adversary $\advA_{KR}$ that simply returns $0^k$. Since $\forall M\in\msgspace, \forall K, K^* \in \keyspace, \cipherE_{K}(M) = \cipherE_{K^*}(M) = M$, $\advA_{KR}$ achieves advantage 1. Thus, we have shown that TKR $\not \Rightarrow$ KR. 
\end{example}

We now ask whether KR $\Rightarrow$ TKR and prove this with the following theorem. 

\begin{theorem}
	\label{thm-tkr-kr}
	Let $\cipher$ be a cipher with message space $\msgspace$. For any $\TKR_\cipher$-adversary $\advA$, we give a
	$\KR_\cipher$-adversary $\advB$ such that 
	$\AdvTKR{\cipher}{\advA} = \AdvKR{\cipher}{\advB}$, where the runtime and query usage of $\advB$ is the same as that of $\advA$. 
\end{theorem}

%[\thref{thm-tkr-kr}]

\begin{proof}
	We are given an adversary $\advA$ that wins the $\TKR_\cipher$ game with advantage $\AdvTKR{\cipher}{\advA}$, meaning that $\advA$ will return the target key chosen by the game with probability $\AdvTKR{\cipher}{\advA}$. We now want to construct an adversary $\advB$ that wins the $\KR_\cipher$ game and do so with the following.
	\begin{center}
	\fpage{.23}{
		\underline{\textbf{adversary } $\advB^\Fn$} \\
		$K^* \getsr \advA^\Fn$ \\
		If $\advA$ made no queries then \\
		\ind $M \getsr \msgspace$ ; $C \gets \Fn(M)$ \\
		Return $K^*$	
	}
	\end{center}

	$\advB$ is given access to its oracle $\Fn$, and it runs $\advA$ using this same oracle. Notice that $\advB$ can simply provide $\advA$ its own oracle because the distribution of outputs for oracle $\Fn$ in game $\TKR_\cipher$ and for oracle $\Fn$ in game $\KR_\cipher$ are equivalent. This is known as an \textit{elementary wrapper}: a reduction that runs an adversary once and simulates an oracle in a simple and efficient way \cite{BonehShoupBook}.
	
	Now $\advA$ returns the precise target key chosen by the game, so $\advB$ returns this key because the target key will always be consistent with all queries. In the case that $\advA$ makes no queries to oracle $\Fn$, $\advB$ would automatically lose the game, so it makes a query to $\Fn$ with a randomly chosen message. $\AdvKR{\cipher}{\advB}$ is then the probability that the key returned by $\advA$ is the target key, which is $\AdvTKR{\cipher}{\advA}$.
\end{proof}


In our theorem statements including reductions,  we need to interpret the words
``we give a''. We will focus on concrete, specified reductions. That means that
the adversary $\advB$ not only exists, but is fully specified  --- minus the
details of $\advA$ ---  within the proof.  In particular, if you give someone
$\advA$ then $\advB$ becomes a runnable adversary.  Runnable reductions are generally
speaking easier to interpret when it comes to implied security guarantees. They
even allow us to use the human-ignorance model~\cite{rogaway2006formalizing}
which, roughly, states that a reduction even to a mathematically easy assumption
can still be meaningful. (We will revisit this particular issue with an example
in the context of collision resistance.)
An example of a non-runnable $\advB$ would be one that includes some constant
value that we know exists, but don't know an exact value for. This comes up in
various arguments, and can cause problems in interpreting the reduction in terms
of concrete security.  This issue is subtle and we will revisit it.

The takeaway here is that one interprets ``we give a'' to mean runnable
adversaries that are specified fully in the proof. (Or when brevity is at stake,
specified to a level of detail that the average reader could specify it in
detail easily.)  When we deviate from this convention we should remark on it.



\paragraph{Exhaustive key search.} We now ask whether we can lower-bound (T)KR security in general. We do this by providing a \textit{generic} attack, or an attack that works against any cipher. One such generic attack is the exhaustive key search attack. The pseudocode is shown in \figref{fig:eks}. At a high level, this attack simply chooses a message at random, queries the $\Fn$ oracle to get the corresponding ciphertext, and then brute-force searches through the entire keyspace until it finds the key that outputs the correct ciphertext.  

\begin{wrapfigure}[7]{l}{0pt}
	\fpage{.22}{
		\underline{$\advA^\eks_\Fn$}\\[1pt]
		$M \getsr \msgspace$ \\
		$C \gets \Fn(M)$ \\
		For $K^* \in \keyspace$ do: \\
		\ind If $C = \cipherE(K^*, M)$ then \\
		\ind\ind Return $K^*$ \\
		Return $\bot$
	}
	\caption{The exhaustive key search attack.}
	\label{fig:eks}
\end{wrapfigure} 

We know that $\AdvKR{\cipher}{\advA_\eks} = 1$ since a consistent key is guaranteed to exist. However, notice that finding $\AdvTKR{\cipher}{\advA_\eks}$ is trickier: $\advA_\eks$ might return a consistent key that is not necessarily the target key. For instance, this attack would not work on the identity map cipher since every key is consistent. For ``real'' ciphers, we expect this to be close to 1. 
The worst-case running time for this attack is $|\keyspace|$, while the expected running time is $|\keyspace|/2$.

\paragraph{Computational security.} Computational security presents a large paradigm shift from previous notions. It focuses on computationally-bound adversaries. For instance, an exhaustive key search attack is clearly not computationally efficient for large key spaces and is thus not considered a threat in practice. We measure computational costs by assuming abstract unit costs of (most) operations. This is course-grained but useful for our purposes. 

We have shown previously that TKR is not a good security notion, but we now ask whether KR is an improved definition. In particular, the identity cipher has been shown to be secure under TKR security, yet it is insecure under KR security, which is clearly an improvement. However, KR does not imply message confidentiality: it is a necessary but not sufficient goal. We now move on to very different notions of security for ciphers.

\paragraph{PRF security.} A standard goal for cipher security is security in the sense of pseudorandom permutations and/or pseudorandom functions. For simplicity, we will focus on \textbf{block ciphers}, which for keyspace $\keyspace=\bits^k$ and message space $\msgspace=\bits^n$ are defined by $\cipherE : \bits^k \times \{0,1\}^n \to \bits^n$. Let $\Perm(n)$ be the set of all permutations on $n$ bits. Notice that since $|\bits^n| = 2^n$, then $|\Perm(n)| = 2^n!$. Let $\Func(n,n)$ be the set of all functions from $\bits^n \to \bits^n$. Note that $|\Func(n,n)| = (2^n)^{2^n}$.

We now define a \textbf{pseudorandom function} (PRF) as a function that is indistinguishable from a random function (RF). At a high level this means that the input-output behavior of some block cipher $\cipherE_K$ ``looks like'' the input-output behavior of a random function assuming key $K$ is kept secret. There are two games defined for PRF security: PRF1 and PRF0. The pseudocode for both is provided in \figref{fig:prf}. In PRF1, the adversary has access to an $\Fn$ oracle that returns the output from the block cipher $\cipherE_K$. However, in PRF0 the adversary instead receives the output from a random function $\rho$ when it queries the $\Fn$ oracle. The adversary $\advA$ does not know in which game it is playing and must query the $\Fn$ oracle to distinguish between $\cipherE_K$ and $\rho$. Adversary $\advA$ returns a bit signifying which game it believes it is in. The PRF advantage for $\advA$ is defined as 
\begin{equation*}
\AdvPRF{\cipher}{\advA} = \left| \Prob{\PRF1_\cipher^\advA\Rightarrow 1} 
- \Prob{\PRF0_\cipher^\advA\Rightarrow1} \right|.
\end{equation*}

The adversary $\advA$ wins if the probability that $\advA$ outputs 1 in game $\PRF1_\cipher^\advA$ is far greater than the probability that it outputs 1 in game $\PRF0_\cipher^\advA$. In particular, notice that if $\advA$ simply always output 1, $\AdvPRF{\cipher}{\advA}$ would be 0 as expected, since $\advA$ did not successfully distinguish $\cipher$ from a random function. 

\begin{figure}
	\centering
	\hfpages{.15}{
		\underline{$\PRF1_{\cipher}^\advA$}\\
		$K \getsr \keyspace$\\
		$b' \getsr \advA^\Fn$\\
		Return $b'$\medskip
		
		\underline{$\Fn(M)$}\\
		Return $\cipherE_K(M)$
	}{
		\underline{$\PRF0_{\cipher}^\advA$}\\
		$\rho \getsr \Func(n,n)$\\
		$b' \getsr \advA^\Fn$\\
		Return $b'$\medskip
		
		\underline{$\Fn(M)$}\\
		Return $\rho(M)$
	}	
\caption{The PRF security games.}
\label{fig:prf}
\end{figure} 

Just as we provided a generic attack for TKR security using the exhaustive key search attack, is there a generic distinguishing attack for any cipher? One interesting observation is that for a given key, a block cipher $\cipherE_K$ is a permutation, meaning that two different inputs cannot produce the same output. (If this were not the case, decryption would be impossible.) However, a random function simply chooses outputs at random, so it is entirely possible for two different inputs to produce the same output. The probability of choosing $q$ values at random from $\{0,1\}^n$ and for two of these values to be the same is approximately $\frac{q^2}{2^n}$. This is colloquially known as the \textbf{birthday paradox}, since it implies that the number of people expected to produce two individuals with the same birthday is far fewer than what one might expect. 

If $\advA$ were to query its $\Fn$ oracle enough times, eventually the probability that a repeat value is produced would be large enough and $\advA$ could then check to see if such a repeat value exists. If no repeat occurs, then $\advA$ can assume it is in game $\PRF1_{\cipher}$; otherwise, $\advA$ must be in game $\PRF0_{\cipher}$. This attack is called the \textbf{birthday attack}. The pseudocode for this adversary is defined below.
 
\begin{center}
\fpage{.35}{
	\underline{\textbf{adversary} $\advA^\Fn_{\text{bday}}$} \\
	Let $M_1, M_2, \cdots, M_q \gets \{0,1\}^n$ be distinct \\
	For $i=1, \cdots, q$ do $C_i \gets \Fn(M_i)$ \\
	If $C_1, \cdots, C_q$ are all distinct then return 1 \\
	Else return 0	
}
\end{center}

In addition to creating $q$ messages and querying $\Fn$ $q$ times, $\advA_{\text{bday}}$ must check to see if there are any duplicates in its answered queries. Overall, $\advA_{\text{bday}}$ will then have running time of $\calO(q)$.
To bound the advantage of $\advA_{\text{bday}}$, first notice that in game $\PRF1_{\cipher}$, $\Fn$ outputs the value from $\cipher$, so all output values will be distinct. Thus, $\advA_{\text{bday}}$ will always return 1 and $\Prob{\PRF1_\cipher\Rightarrow 1}=1$. The probability that $\advA_{\text{bday}}$ returns 1 in game $\PRF0_{\cipher}$ is trickier to bound. To do so, we first define $C(N,q)$ as the probability that in the event of choosing $q$ values uniformly at random from set $\{1,\cdots,N\}$, not all of the values chosen are distinct. In game $\PRF0_{\cipher}$, $\Fn$ returns the output from a random function and since $M_1, \cdots, M_q$ are all distinct, then $C_1, \cdots, C_q$ are independently distributed, random values from $\bits$. The probability of all these values being distinct is the probability that there does not exist a collision, which is $1-C(N,q)$, where $N=2^n$. $C(N,q)$ is the birthday bound, so it can be lower-bounded by $\frac{q^2}{2^n}$. 
The PRF-advantage of $\advA^\Fn_{\text{bday}}$ is then defined as 
\begin{align*}
\AdvPRF{\cipher}{\advA_\text{bday}} &= \left| \Prob{\PRF1_\cipher^{\advA_\text{bday}}\Rightarrow 1} 
- \Prob{\PRF0_\cipher^{\advA_\text{bday}}\Rightarrow1} \right| \\
&= 1 - (1 - C(N,q)) \\ 
&= C(N,q) \\ 
&\geq \frac{q^2}{2^n}.
\end{align*}

In order for $\advA_{\text{bday}}$ to have a high probability of succeeding, we expect $q \approx 2^{n/2}$. This means $\advA_{\text{bday}}$ will also have running time of about $2^{n/2}$. For large values of $n$, this becomes an impractical attack. 


\paragraph{PRP security.} We define a \textbf{pseudorandom permutation} (PRP) as a function that is indistinguishable from a random permutation (RP). The games for PRP security are provided in \figref{fig:prp}. These games work similarly to the PRF games but now utilize a random permutation in $\PRP0_\cipher^\advA$ rather than a random function. The PRP advantage for $\advA$ is defined as 
\begin{equation*}
\AdvPRP{\cipher}{\advA} = \left| \Prob{\PRP1_\cipher^\advA\Rightarrow 1} 
- \Prob{\PRP0_\cipher^\advA\Rightarrow1} \right|.
\end{equation*}

\begin{figure}
	\centering
	\hfpages{.15}{
		\underline{$\PRP1_{\cipher}^\advA$}\\
		$K \getsr \keyspace$\\
		$b' \getsr \advA^\Fn$\\
		Return $b'$\medskip
		
		\underline{$\Fn(M)$}\\
		Return $\cipherE_K(M)$
	}{
		\underline{$\PRP0_{\cipher}^\advA$}\\
		$\pi \getsr \Perm(n)$\\
		$b' \getsr \advA^\Fn$\\
		Return $b'$\medskip
		
		\underline{$\Fn(M)$}\\
		Return $\pi(M)$
	}
\caption{The PRP security games.}
\label{fig:prp}	
\end{figure}

Considering that these notions are similar, can we relate them to each other? Intuitively, there is no difference between a random function and a random permutation when observing only a few input-output pairs, as long as the ciphertext space $n$ is sufficiently large. We formalize this intuition with the following lemma. 

\begin{lem}[PRF-PRP Switching Lemma]
	\label{switching-lem}
	Let $\cipher$ be a cipher with ciphertext space $\bits^n$. 
	Let $\advA$ be an adversary making at most $q$ queries. Then
	\bnm
	\left| \Prob{\PRF0_\cipher^\advA\Rightarrow 1} 
	- \Prob{\PRP0_\cipher^\advA\Rightarrow1} \right| \le \frac{q^2}{2^n}  \;.
	\enm
\end{lem}

The intuition for the following proof is that if you have oracle access to a random function or a random permutation, then you need to make enough queries to witness a collision, as determined by the birthday bound. 

One's first instinct might be to bound the difference using a conditioning argument. For instance, let $\mathsf{Dist}$ be the event that in game $\PRF0_{\cipher}^\advA$ all values returned from oracle $\Fn$ are distinct. Then one might say that $\Prob{\PRP1_\cipher^\advA\Rightarrow 1} =   \Prob{\PRP0_\cipher^\advA\Rightarrow1 | \mathsf{Dist}}$. However, this is incorrect and in fact $\Prob{\PRP1_\cipher^\advA\Rightarrow 1} \neq   \Prob{\PRP0_\cipher^\advA\Rightarrow1 | \mathsf{Dist}}$. Refer to \cite{bellare2006multi} for further technical details. 

To correctly prove this, we will instead use a game-playing argument. We first provide the following definitions and lemma. 

\begin{definition}
	A \textbf{flag} is a variable in a pseudocode game that is set upon the occurrence of some event in the game. 
\end{definition}

Typically, games will utilize a flag called \textit{bad} which is set to $\true$.  

\begin{definition}
	Games $\G1$ and $\G2$ are \textbf{identical-until-bad} if they both contain a flag $\bad$  and their code differs only in statements following the setting of $\bad$ to $\true$. 
\end{definition} 

\begin{lem}[Fundamental Lemma of game playing \cite{bellare2006security}]
	Let $\G$, $\Hgame$ be games that are identical-until-bad and let $y$ be any
	value. Then
	\bnm
	\big| \Prob{\G\Rightarrow y} 
	- \Prob{\Hgame\Rightarrow y} \big| \le \Prob{\Hgame\setsbad} = \Prob{\G\setsbad}  \;.
	\enm
\end{lem}

Stated another way, this lemma tells us about the advantage an adversary gains in distinguishing a pair of identical-until-bad games, $\G$ and $\Hgame$. Since $\G$ and $\Hgame$ only differ upon the setting of flag $\bad$, then intuitively we can see that the advantage of an adversary to distinguish between these games must be at most the probability that $\bad$ is set during its execution.

The overall technique we will implement here (and generally in game-playing arguments) is to create a chain of games that are identical-until-bad. We can then invoke the Fundamental Lemma of game playing to upper-bound the adversary's advantage by the probability that $\bad$ gets set in either game. We can slowly modify the games in ways that change the probability of $\bad$ being set until we reach some terminal game where we can utilize conventional probabilistic methods to bound the probability of setting $\bad$. Note that the following proof introduces a $\bad$ flag that can be immediately bounded by traditional means without modification, although future proofs we will see will require further transformations. 

\begin{proof}[Proof of \lemref{switching-lem}]
	 We define the games in \figref{fig:switching}. Notice that the output from game $\G0$ has an identical distribution to that of game $\PRP0_\cipher^\advA$. The only difference between them is that game $\PRP0_\cipher^\advA$ chooses a random permutation and returns the output from that, while game $\G0$ chooses unique values at random as $\advA$ makes queries to $\Fn$. Then $\Prob{\PRP0_\cipher^\advA\Rightarrow1} = \Prob{\G0}$. Game $\G1$ includes the boxed statement and also has an identical output distribution to that of game $\G0$. It simply chooses an output value at random, and if it detects a repeat it then chooses another unique value. In the case of a repeat, it also sets the $\bad$ flag to $\true$. We then have that $\Prob{\G1} = \Prob{\G0}$. We next transition to game $\G2$ and notice that $\G1$ and $\G2$ are \textbf{identical-until-bad}. The Fundamental Lemma of game playing then states that $\Prob{\G1} \leq \Prob{\G2} + \Prob{\bad \text{ set to } \true}$. Game $\G2$ returns values chosen at random and allows for repeat values, so it has an identical output distribution to $\PRF0_\cipher^\advA$. This means $\Prob{\PRF0_\cipher^\advA\Rightarrow1} = \Prob{\G2}$. Finally, the probability that $\bad$ is set to $\true$ is the probability that a random value is chosen by $\Fn$ such that it is not distinct, which is bounded by the birthday bound. We then have the following:
	 
	 \begin{figure}
	 	\centering
	 	\hfpagess{.20}{.20}{
	 		\underline{$\G0$}\\[2pt]
	 		$b' \getsr \advA^\Fn$\\
	 		Return $b'$\medskip
	 		
	 		\underline{$\Fn(M)$}\\
	 		If $\TabF[M] = \bot$ then\\
	 		\ind $\TabF[M] \getsr \bits^n \setminus \TabF$\\
	 		Return $\TabF[M]$
	 	}{
	 		\underline{\fbox{$\G1$} \;\;\; $\G2$}\\[2pt]
	 		$b' \getsr \advA^\Fn$\\
	 		Return $b'$\medskip
	 		
	 		\underline{$\Fn(M)$}\\
	 		$C \getsr \bits^n$\\
	 		If $C \in \TabF$ then\\
	 		\ind $\badtrue$\\
	 		\ind \fbox{$C \getsr \bits^n \setminus \TabF$}\\
	 		$\TabF[M] \gets C$\\
	 		Return $\TabF[M]$
	 	}
	 	\caption{The games for the proof of the PRF-PRP Switching Lemma (\lemref{switching-lem}).}
	 	\label{fig:switching}	
	 \end{figure} 
	 
	 \begin{align*}
	 \left| \Prob{\PRP0_\cipher^\advA\Rightarrow 1} 
	 - \Prob{\PRF0_\cipher^\advA\Rightarrow1} \right|  
	 &=  \left|\Prob{\G0} - \Prob{\PRF0_\cipher^\advA\Rightarrow1} \right|  \\
	 &=  \left|\Prob{\G1} - \Prob{\PRF0_\cipher^\advA\Rightarrow1} \right|  \\
	 &\le \left|\Prob{\G2} + \Prob{\bad \text{ set to } \true} - \Prob{\PRF0_\cipher^\advA\Rightarrow1} \right|\\
	 &= \Prob{\bad \text{ set to } \true}\\
	 &\le \frac{q^2}{2^n} \\
	 \end{align*} 
\end{proof}